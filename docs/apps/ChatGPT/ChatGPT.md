ChatGPT に要件定義を手伝ってもらうときに必要なのは、普通に要件定義するときに必要な問いかけと同じだ。

使い方は簡単だけど、重要なのは対象の分野における思考プロセスそのもの。

ChatGPT の思考を助けてやるには、質問の解像度を高めないといけない。

結局、各分野に通じてないと ChatGPT を使っても浅い。

ChatGPT が質問と回答の繰り返しで深掘りしていくのは思考のプロセスそのもの。

今のところ GPT は精度よりも速度を優先した方が使いやすい。

GPT-4 でプロンプトを作り込んで、GPT-3.5 で動かした時の精度を高める方法もある。

ある事柄を ChatGPT に説明させて、「間違いを指摘せよ」と課題を与えるテストがあったとか。
https://dot.asahi.com/aera/2023031500070.html?page=1

特定ドメインに特化するのは ChatGPT に追加学習しないといけないので、ChatGPT だけではできない。補完的なニーズがある。

[GPT-4 以降，英語が最強のプログラミング言語になりつつある状況をまじめに考えてみる．｜落合陽一｜ note](https://note.com/ochyai/n/n594b96588560)

API なら Fine-tuning もできる。

入力を加工するためのライブラリとして、Embedding や LangChain がある。

GPT くらいになると AI かどうかはそこまで重要ではない。
相手の特徴、できることを理解して、相手の理解度を把握するのが大事。

GPT の精度が低かったら「条件や手順を整理してくれ」って命令して確認した方が良さそう。

[【完全保存版】GPT を特定の目的に特化させて扱う (Fine-tuning, Prompt, Index, etc.) - Qiita](https://qiita.com/tmgauss/items/22c4e5e00282a23e569d)

GPT 自体にプロンプトを作ってもらう
「〜したいです。どのようなプロンプトを投げればいいですか？」

目的や仮説を投げてから「まずは理解するために質問して」「話を膨らませるためのトピックを教えて」と広げていく。

OpenAI 公式の事例。
[GitHub - openai/openai-cookbook: Examples and guides for using the OpenAI API](https://github.com/openai/openai-cookbook)

[Prompt Engineering Guide 日本語版](https://www.promptingguide.ai/jp)

GPT で BNF 表記を使うアイデア
https://twitter.com/awakia/status/1641798554623819777

「できないことがあっても教育できる」のが ChatGPT の強みかも。
初めからできるとは限らないけど、信頼して育てるとうまくいく。

どうやって育てるか、学習させるか、あるいはそもそもその仕事をどういう手順で処理するか、はユーザーが知っておかないといけない。

ChatGPT で解決できるのは結局自分が解き方をわかっている問題だけなのかも。

ChatGPT が出力できるもの、主にテキスト、でないと結果を受け取れない。
表データとか文章とか、テキストで扱えるものは大体扱える。

まずはそのまま命令してみて、ChatGPT が「何を知らないのか」を観察しないといけない。子供に仕事を任せるのと同じ。

知らない命令をエラーにしないのが人間や GPT の強みでもあり、使いづらい部分でもある。

ChatGPT は、子供を扱うのと同じように扱う。
子供に何らかの仕事を任せるなら、まずはやり方を教えてあげないといけない。しかも、わからなくても「わからない」とは返さない。

ChatGPT や人間は、命令の結果に満足できなかったら、もっと具体的にやり方を教えて結果を修正する必要がある。

プロンプトエンジニアリングは人間に指示を与えて、結果を絞り込んでいくのと似ている。

- 小さく試して、フィードバックを与える。
- 事例や結果の中で気に入った候補を指定する。
- どこで認識が合っていないのか観察する。

相手が「知ったかぶっていること」にどうやって気づくか。

エラーや例外を出さないのは「知ったかぶり」だ。
